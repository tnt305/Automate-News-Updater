{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_kay = \"cpk_ec375cb3e934458fbebeebaabf0b5ecb.542a8764df495fa59e86c4a846970e1e.6cFExcSFgaUIqv4ONzES5OQfIyhzUEWX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m                         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError parsing chunk: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvoke_chute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/asyncio/runners.py:186\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "async def invoke_chute():\n",
    "    api_token = api_kay  # Thay b·∫±ng API token th·ª±c t·∫ø c·ªßa b·∫°n\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + api_token,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    body = {\n",
    "        \"model\": \"deepseek-ai/DeepSeek-V3-0324\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Tell me a 250 word story.\"\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": True,\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\n",
    "            \"https://llm.chutes.ai/v1/chat/completions\", \n",
    "            headers=headers,\n",
    "            json=body\n",
    "        ) as response:\n",
    "            async for line in response.content:\n",
    "                line = line.decode(\"utf-8\").strip()\n",
    "                if line.startswith(\"data: \"):\n",
    "                    data = line[6:]\n",
    "                    if data == \"[DONE]\":\n",
    "                        break\n",
    "                    try:\n",
    "                        chunk = data.strip()\n",
    "                        if chunk:\n",
    "                            print(chunk)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error parsing chunk: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(invoke_chute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing a **100,000,000,000-word story** is physically impossible‚Äîit would take roughly **3,000 years** to read aloud nonstop, and storing it digitally would require **200 terabytes** of text (far exceeding all published literature combined).  \n",
      "\n",
      "### Instead, here‚Äôs the **shortest possible version** of an *infinite* story:  \n",
      "**\"And then‚Ä¶ everything kept happening‚Äîforever. The end?\"**  \n",
      "\n",
      "### Want something more engaging? Try these:  \n",
      "1. **A 1-sentence sci-fi epic**:  \n",
      "   *\"The last human uploaded their mind into a black hole, only to discover it whispered back: ‚ÄòI‚Äôve been waiting.‚Äô\"*  \n",
      "\n",
      "2. **A never-ending joke**:  \n",
      "   *\"A dyslexic robot walks into a bar‚Ä¶ then a bar‚Ä¶ then a bar‚Ä¶ then a‚Äî\"*  \n",
      "\n",
      "3. **A fractal story**:  \n",
      "   *\"They wrote a story about writing a story about writing a story about‚Äî\"*  \n",
      "\n",
      "For scale: *War and Peace* is ~600,000 words. A 100B-word \"story\" would be **166,666 copies** of it. Even AI would collapse trying.  \n",
      "\n",
      "Want a **custom short story** instead? I‚Äôd love to help! Just say the word. üòä"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "async def invoke_chute():\n",
    "    api_token = \"cpk_ec375cb3e934458fbebeebaabf0b5ecb.542a8764df495fa59e86c4a846970e1e.6cFExcSFgaUIqv4ONzES5OQfIyhzUEWX\"  # Thay b·∫±ng API token th·ª±c t·∫ø c·ªßa b·∫°n\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + api_token,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    body = {\n",
    "        \"model\": \"deepseek-ai/DeepSeek-V3-0324\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Tell me a 100000000000 word story.\"\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": True,\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    items = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\n",
    "            \"https://llm.chutes.ai/v1/chat/completions\", \n",
    "            headers=headers,\n",
    "            json=body\n",
    "        ) as response:\n",
    "            async for line in response.content:\n",
    "                line = line.decode(\"utf-8\").strip()\n",
    "                if line.startswith(\"data: \"):\n",
    "                    data = line[6:]\n",
    "                    if data == \"[DONE]\":\n",
    "                        break\n",
    "                    try:\n",
    "                        chunk = data.strip()\n",
    "                        # Ki·ªÉm tra chunk kh√¥ng r·ªóng v√† kh√¥ng ph·∫£i \"[]\"\n",
    "                        if chunk and chunk != \"[]\":\n",
    "                            parsed_chunk = json.loads(chunk)\n",
    "                            # Ki·ªÉm tra choices c√≥ d·ªØ li·ªáu kh√¥ng\n",
    "                            if \"choices\" in parsed_chunk and parsed_chunk[\"choices\"]:\n",
    "                                item = parsed_chunk[\"choices\"][0][\"delta\"][\"content\"]\n",
    "                                if item:  # Ch·ªâ th√™m n·∫øu item kh√¥ng r·ªóng\n",
    "                                    print(item, end=\"\", flush=True)\n",
    "                                    # ·ªû ƒë√¢y b·∫°n c√≥ th·ªÉ x·ª≠ l√Ω item n·∫øu c·∫ßn, kh√¥ng print\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error parsing JSON: {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing chunk: {e}\")\n",
    "    \n",
    "    # Tr·∫£ v·ªÅ c√¢u ho√†n ch·ªânh\n",
    "    return \"\".join(items)\n",
    "\n",
    "# H√†m main ƒë·ªÉ ch·∫°y v√† l·∫•y k·∫øt qu·∫£\n",
    "async def main():\n",
    "    await invoke_chute()\n",
    " # In c√¢u ho√†n ch·ªânh sau khi xong\n",
    "\n",
    "if asyncio.get_event_loop().is_running():\n",
    "    # Cho Jupyter Notebook ho·∫∑c m√¥i tr∆∞·ªùng c√≥ v√≤ng l·∫∑p s·∫µn\n",
    "    await invoke_chute()  # G·ªçi tr·ª±c ti·∫øp trong cell Jupyter\n",
    "else:\n",
    "    # Cho file .py ƒë·ªôc l·∫≠p\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepseek-ai/DeepSeek-V3-0324\n",
    "# Qwen/Qwen2.5-VL-32B-Instruct\n",
    "# unsloth/gemma-3-1b-it\n",
    "# unsloth/gemma-3-12b-it\n",
    "# unsloth/gemma-3-4b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
